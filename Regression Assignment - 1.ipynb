{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddabba4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Q1. Difference Between Simple and Multiple Linear Regression + Examples**\n",
    "\n",
    "**Simple Linear Regression**:  \n",
    "This involves one independent variable (predictor) and one dependent variable (response). It models the relationship between them using a straight line.\n",
    "\n",
    "**Formula**:  \n",
    "\\[\n",
    "y = \\beta_0 + \\beta_1 x + \\varepsilon\n",
    "\\]  \n",
    "Where:\n",
    "- \\( y \\) = dependent variable  \n",
    "- \\( x \\) = independent variable  \n",
    "- \\( \\beta_0 \\) = intercept  \n",
    "- \\( \\beta_1 \\) = slope  \n",
    "- \\( \\varepsilon \\) = error term\n",
    "\n",
    "**Example**:  \n",
    "Predicting house price based on size:  \n",
    "> Price = \\( \\beta_0 \\) + \\( \\beta_1 \\times \\text{Size (sq ft)} \\)\n",
    "\n",
    "---\n",
    "\n",
    "**Multiple Linear Regression**:  \n",
    "This involves **two or more** independent variables predicting one dependent variable.\n",
    "\n",
    "**Formula**:  \n",
    "\\[\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n + \\varepsilon\n",
    "\\]\n",
    "\n",
    "**Example**:  \n",
    "Predicting house price based on size, number of bedrooms, and location:  \n",
    "> Price = \\( \\beta_0 \\) + \\( \\beta_1 \\times \\text{Size} \\) + \\( \\beta_2 \\times \\text{Bedrooms} \\) + \\( \\beta_3 \\times \\text{Location Score} \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. Assumptions of Linear Regression and How to Check Them**\n",
    "\n",
    "1. **Linearity**:  \n",
    "   Relationship between independent and dependent variables is linear.  \n",
    "   🔍 *Check*: Use scatter plots or residual vs fitted plots.\n",
    "\n",
    "2. **Independence of errors**:  \n",
    "   Residuals should not be correlated.  \n",
    "   🔍 *Check*: Use the Durbin-Watson test.\n",
    "\n",
    "3. **Homoscedasticity**:  \n",
    "   Constant variance of residuals across all levels of independent variables.  \n",
    "   🔍 *Check*: Plot residuals vs predicted values — look for a \"funnel\" shape.\n",
    "\n",
    "4. **Normality of errors**:  \n",
    "   Residuals should be normally distributed.  \n",
    "   🔍 *Check*: Histogram or Q-Q plot of residuals; Shapiro-Wilk test.\n",
    "\n",
    "5. **No multicollinearity** (for multiple regression):  \n",
    "   Predictors shouldn’t be highly correlated.  \n",
    "   🔍 *Check*: Use VIF (Variance Inflation Factor).\n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. Interpreting Slope and Intercept in Linear Regression + Real-World Example**\n",
    "\n",
    "**Slope (\\( \\beta_1 \\))**: Change in the dependent variable for a one-unit change in the independent variable.\n",
    "\n",
    "**Intercept (\\( \\beta_0 \\))**: Predicted value of the dependent variable when all independent variables are 0.\n",
    "\n",
    "**Example**:  \n",
    "Let’s say we model:  \n",
    "> Salary = 30,000 + 2,000 × Years of Experience\n",
    "\n",
    "- **Intercept (30,000)**: Base salary with 0 years of experience.  \n",
    "- **Slope (2,000)**: For each additional year of experience, salary increases by $2,000.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. What is Gradient Descent and Its Role in Machine Learning?**\n",
    "\n",
    "**Gradient Descent** is an optimization algorithm used to minimize a function — commonly the **loss function** in machine learning.\n",
    "\n",
    "**Concept**:\n",
    "- Imagine a valley (loss function graph).\n",
    "- You want to get to the bottom (minimum loss).\n",
    "- You take steps in the direction of the steepest descent (negative gradient).\n",
    "\n",
    "**Steps**:\n",
    "1. Start with random values of parameters (like slope and intercept).\n",
    "2. Compute the loss (e.g., MSE).\n",
    "3. Calculate gradients (partial derivatives).\n",
    "4. Update parameters:  \n",
    "   \\[\n",
    "   \\theta := \\theta - \\alpha \\frac{\\partial L}{\\partial \\theta}\n",
    "   \\]\n",
    "   Where \\( \\alpha \\) is the **learning rate**.\n",
    "\n",
    "**Use in Machine Learning**:\n",
    "- Used to train models like linear regression, logistic regression, neural networks.\n",
    "- Helps in finding the best-fit line or decision boundary by minimizing error.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452dfe7",
   "metadata": {},
   "source": [
    "\n",
    "### **Q5. Describe the Multiple Linear Regression Model. How Is It Different from Simple Linear Regression?**\n",
    "\n",
    "**Multiple Linear Regression (MLR)** models the relationship between a dependent variable and **two or more** independent variables.\n",
    "\n",
    "**Equation**:  \n",
    "\\[\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n + \\varepsilon\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( y \\): Dependent variable  \n",
    "- \\( x_1, x_2, ..., x_n \\): Independent variables  \n",
    "- \\( \\beta_0 \\): Intercept  \n",
    "- \\( \\beta_1, ..., \\beta_n \\): Coefficients (slopes)  \n",
    "- \\( \\varepsilon \\): Error term\n",
    "\n",
    "**Difference from Simple Linear Regression (SLR)**:\n",
    "- **SLR**: 1 independent variable (e.g., Predicting salary from experience).\n",
    "- **MLR**: 2+ independent variables (e.g., Predicting salary from experience, education, and age).\n",
    "\n",
    "---\n",
    "\n",
    "### **Q6. Explain Multicollinearity in Multiple Linear Regression. How to Detect and Address It?**\n",
    "\n",
    "**Multicollinearity** occurs when two or more independent variables are **highly correlated** — they provide redundant information.\n",
    "\n",
    "#### ❗ Why It’s a Problem:\n",
    "- Makes it hard to interpret coefficients.\n",
    "- Increases the standard error → unreliable estimates.\n",
    "- May cause instability in the model.\n",
    "\n",
    "#### 🔍 How to Detect:\n",
    "1. **Correlation matrix** — Check for high pairwise correlations (e.g., > 0.8).\n",
    "2. **Variance Inflation Factor (VIF)** —  \n",
    "   - VIF > 5 or 10 is usually a red flag.\n",
    "\n",
    "#### 🛠️ How to Fix:\n",
    "- Remove or combine correlated predictors.\n",
    "- Use dimensionality reduction (e.g., **PCA**).\n",
    "- Use **Ridge Regression** or **Lasso**, which can handle multicollinearity better.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q7. What Is Polynomial Regression? How Is It Different from Linear Regression?**\n",
    "\n",
    "**Polynomial Regression** is a type of linear regression where the relationship between the independent and dependent variable is modeled as an **nth-degree polynomial**.\n",
    "\n",
    "**Equation (for degree 2)**:  \n",
    "\\[\n",
    "y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\varepsilon\n",
    "\\]\n",
    "\n",
    "#### 🆚 Difference from Linear Regression:\n",
    "- **Linear Regression**: Models straight-line relationships.\n",
    "- **Polynomial Regression**: Can model curves (non-linear relationships).\n",
    "\n",
    "Despite the curve, it’s still a **linear model in terms of the coefficients**, so it's solvable with linear regression techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q8. Advantages and Disadvantages of Polynomial Regression**\n",
    "\n",
    "#### ✅ Advantages:\n",
    "- Can model non-linear relationships effectively.\n",
    "- More flexible than simple linear models.\n",
    "\n",
    "#### ❌ Disadvantages:\n",
    "- Prone to **overfitting**, especially with high-degree polynomials.\n",
    "- **Extrapolation** (predictions outside the data range) becomes unreliable.\n",
    "- Less interpretable than linear models.\n",
    "\n",
    "#### 🔄 When to Use Polynomial Regression:\n",
    "- When data clearly shows a **non-linear trend** that a straight line can’t capture.\n",
    "- Example: Modeling the effect of time on temperature, where there’s a peak and decline (e.g., daily temperature changes).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1d208",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
