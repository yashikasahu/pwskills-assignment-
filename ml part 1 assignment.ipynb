{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413d3d02",
   "metadata": {},
   "source": [
    "# Q1: Explain the following with an example:F\n",
    "1) Artificial IntelligencJ\n",
    "2) Machine Learnin,\n",
    "3) Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4e947",
   "metadata": {},
   "source": [
    "- **Artificial Intelligence (AI)**: Broad field of creating systems that mimic human intelligence for tasks like reasoning or decision-making.  \n",
    "  **Example**: Siri answering “Find a nearby restaurant” by processing voice, searching, and suggesting options.  \n",
    "\n",
    "- **Machine Learning (ML)**: Subset of AI where systems learn from data to make predictions without explicit rules.  \n",
    "  **Example**: Siri learns from your past choices (e.g., preferring Italian) to recommend “Luigi’s Pizzeria.”  \n",
    "\n",
    "- **Deep Learning (DL)**: Subset of ML using neural networks to analyze complex data like images or audio.  \n",
    "  **Example**: Siri’s speech recognition uses a deep neural network to convert your voice command into text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32504f60",
   "metadata": {},
   "source": [
    "# Q2: What is supervised learning? List some examples of supervised learning.\n",
    "**Supervised Learning**: A type of machine learning where a model is trained on labeled data (input-output pairs) to predict outcomes for new data. The model learns patterns from examples where the correct answer is provided.\n",
    "\n",
    "**Examples**:\n",
    "1. **Email Spam Detection**: Model trained on emails labeled \"spam\" or \"not spam\" to classify new emails.\n",
    "2. **House Price Prediction**: Model uses features (e.g., size, location) and labeled prices to predict prices for new houses.\n",
    "3. **Image Classification**: Model trained on images labeled with categories (e.g., \"cat\" or \"dog\") to identify objects in new images.\n",
    "4. **Sentiment Analysis**: Model trained on text labeled as \"positive\" or \"negative\" to determine sentiment in new reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f6e16",
   "metadata": {},
   "source": [
    "# Q3: What is unsupervised learning? List some examples of unsupervised learning.\n",
    "**Unsupervised Learning**: A type of machine learning where the model analyzes unlabeled data to find patterns or structures without predefined outputs. It identifies hidden relationships or groupings in the data.\n",
    "\n",
    "**Examples**:\n",
    "1. **Customer Segmentation**: Grouping customers based on purchasing behavior without predefined categories.\n",
    "2. **Anomaly Detection**: Identifying unusual patterns in data, like detecting fraudulent transactions.\n",
    "3. **Image Clustering**: Grouping similar images (e.g., landscapes vs. portraits) without labeled categories.\n",
    "4. **Topic Modeling**: Extracting themes from a collection of documents, like identifying topics in news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ba2ca",
   "metadata": {},
   "source": [
    "# Q4: Difference Between AI, ML, DL, and DS\n",
    "\n",
    "- **Artificial Intelligence (AI)**:  \n",
    "  Broad field of creating systems that mimic human intelligence for tasks like reasoning or decision-making.  \n",
    "  **Scope**: Encompasses all methods, including rule-based systems, ML, and DL.  \n",
    "  **Example**: Siri processing voice commands and suggesting restaurants.  \n",
    "\n",
    "- **Machine Learning (ML)**:  \n",
    "  Subset of AI where models learn patterns from data to make predictions without explicit programming.  \n",
    "  **Scope**: Uses algorithms like regression or clustering, relies on labeled or unlabeled data.  \n",
    "  **Example**: Siri predicting restaurant preferences based on past choices.  \n",
    "\n",
    "- **Deep Learning (DL)**:  \n",
    "  Subset of ML using neural networks with many layers to analyze complex data (e.g., images, audio).  \n",
    "  **Scope**: Handles unstructured data, requires large datasets and high compute power.  \n",
    "  **Example**: Siri’s speech recognition using neural networks to convert voice to text.  \n",
    "\n",
    "- **Data Science (DS)**:  \n",
    "  Interdisciplinary field combining stats, programming, and domain knowledge to extract insights from data, often using AI/ML/DL.  \n",
    "  **Scope**: Includes data collection, cleaning, visualization, and modeling, not limited to AI.  \n",
    "  **Example**: Analyzing restaurant review data to identify trends, using ML models or statistical methods.  \n",
    "\n",
    "**Key Difference**: AI is the broadest (smart systems), ML is a subset (learning from data), DL is a specialized ML technique (neural networks), and DS is a wider field (data insights, including AI/ML)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b226b",
   "metadata": {},
   "source": [
    "# Q5: Main Differences Between Supervised, Unsupervised, and Semi-Supervised Learning\n",
    "\n",
    "- **Supervised Learning**:\n",
    "  - **Definition**: Model trains on labeled data (input-output pairs) to predict outcomes for new data.\n",
    "  - **Data**: Fully labeled (e.g., emails tagged as \"spam\" or \"not spam\").\n",
    "  - **Goal**: Learn mapping from inputs to known outputs (classification or regression).\n",
    "  - **Examples**: Spam detection, house price prediction.\n",
    "  - **Pros**: Accurate with clear labels, predictable outcomes.\n",
    "  - **Cons**: Requires extensive labeled data, time-consuming to label.\n",
    "\n",
    "- **Unsupervised Learning**:\n",
    "  - **Definition**: Model analyzes unlabeled data to find patterns or groupings without predefined outputs.\n",
    "  - **Data**: No labels (e.g., customer purchase data without categories).\n",
    "  - **Goal**: Discover hidden structures (clustering or dimensionality reduction).\n",
    "  - **Examples**: Customer segmentation, anomaly detection.\n",
    "  - **Pros**: Works with unlabeled data, finds unknown patterns.\n",
    "  - **Cons**: Results harder to interpret, less control over outcomes.\n",
    "\n",
    "- **Semi-Supervised Learning**:\n",
    "  - **Definition**: Model trains on a mix of labeled and unlabeled data, using labeled data to guide learning on unlabeled data.\n",
    "  - **Data**: Small labeled dataset + large unlabeled dataset (e.g., a few labeled images, many unlabeled).\n",
    "  - **Goal**: Improve predictions by leveraging both data types, balancing accuracy and scalability.\n",
    "  - **Examples**: Image classification with few labeled images, text classification with partial labels.\n",
    "  - **Pros**: Reduces labeling effort, leverages abundant unlabeled data.\n",
    "  - **Cons**: Complex to implement, may be less accurate than fully supervised.\n",
    "\n",
    "**Key Differences**:\n",
    "- **Data**: Supervised uses fully labeled data, unsupervised uses none, semi-supervised uses both.\n",
    "- **Objective**: Supervised predicts specific outputs, unsupervised finds patterns, semi-supervised combines both.\n",
    "- **Use Case**: Supervised for clear tasks, unsupervised for exploratory analysis, semi-supervised for limited labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ec2da",
   "metadata": {},
   "source": [
    "# Q6: What is Train, Test, and Validation Split? Importance of Each Term\n",
    "\n",
    "**Train, Test, and Validation Split**: Dividing a dataset into three subsets to build, tune, and evaluate a machine learning model effectively.\n",
    "\n",
    "- **Training Set**:\n",
    "  - **Definition**: Data used to train the model, allowing it to learn patterns (e.g., weights in a neural network).\n",
    "  - **Importance**: Provides the foundation for the model to learn relationships between inputs and outputs, directly affecting its predictive ability.\n",
    "  - **Example**: 60-80% of data, like labeled images to teach a model to recognize cats.\n",
    "\n",
    "- **Validation Set**:\n",
    "  - **Definition**: Data used to tune the model’s hyperparameters (e.g., learning rate) and assess performance during training.\n",
    "  - **Importance**: Helps optimize the model and prevent overfitting by providing feedback on generalization to unseen data without touching the test set.\n",
    "  - **Example**: 10-20% of data, used to adjust model settings during training.\n",
    "\n",
    "- **Test Set**:\n",
    "  - **Definition**: Data reserved to evaluate the final model’s performance after training and tuning.\n",
    "  - **Importance**: Provides an unbiased measure of the model’s accuracy and generalization to new data, simulating real-world performance.\n",
    "  - **Example**: 10-20% of data, used once to report final metrics like accuracy.\n",
    "\n",
    "**Key Importance**:\n",
    "- **Training**: Builds the model’s knowledge.\n",
    "- **Validation**: Ensures the model is tuned and generalizes well, avoiding overfitting.\n",
    "- **Test**: Confirms the model’s real-world readiness with an independent evaluation.\n",
    "- **Why Split?**: Prevents overfitting, ensures robust performance, and balances model optimization with fair evaluation. Typical split ratios: 70/15/15 or 80/10/10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676afc23",
   "metadata": {},
   "source": [
    "# Q7: How Unsupervised Learning is Used in Anomaly Detection\n",
    "\n",
    "**Unsupervised Learning in Anomaly Detection**: Unsupervised learning identifies anomalies (outliers) in unlabeled data by detecting patterns or structures that deviate significantly from the norm, without requiring predefined labels for \"normal\" or \"anomalous.\"\n",
    "\n",
    "**How It Works**:\n",
    "- **Pattern Discovery**: Algorithms like clustering (e.g., K-Means, DBSCAN) or dimensionality reduction (e.g., PCA) group similar data points based on features.\n",
    "- **Anomaly Identification**: Data points that don’t fit well into clusters, are far from cluster centers, or have unusual feature patterns are flagged as anomalies.\n",
    "- **No Labels Needed**: Since anomalies are rare and labeling is costly, unsupervised methods learn from the data’s inherent structure.\n",
    "\n",
    "**Examples**:\n",
    "1. **Fraud Detection**: Clustering transaction data to flag unusual patterns (e.g., large, irregular purchases) as potential fraud.\n",
    "2. **Network Security**: Using autoencoders to detect abnormal network traffic (e.g., cyberattacks) by reconstructing normal patterns and flagging high reconstruction errors.\n",
    "3. **Manufacturing**: Identifying defective products by detecting outliers in sensor data (e.g., abnormal vibrations) using DBSCAN.\n",
    "\n",
    "**Importance**:\n",
    "- Works with unlabeled data, common in real-world scenarios.\n",
    "- Detects rare or unknown anomalies (e.g., new types of fraud).\n",
    "- Scalable for large datasets where manual labeling is impractical.\n",
    "\n",
    "**Key Algorithms**: K-Means, DBSCAN, Isolation Forest, Autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc4574",
   "metadata": {},
   "source": [
    "# Q8: Commonly Used Supervised and Unsupervised Learning Algorithms\n",
    "\n",
    "**Supervised Learning Algorithms** (used with labeled data for prediction):\n",
    "1. **Linear Regression**: Predicts continuous outputs (e.g., house prices).\n",
    "2. **Logistic Regression**: Classifies binary outcomes (e.g., spam vs. not spam).\n",
    "3. **Decision Trees**: Makes decisions by splitting data into branches (e.g., loan approval).\n",
    "4. **Random Forest**: Ensemble of decision trees for robust classification/regression.\n",
    "5. **Support Vector Machines (SVM)**: Finds optimal boundary for classification (e.g., image classification).\n",
    "6. **K-Nearest Neighbors (KNN)**: Classifies based on closest data points (e.g., digit recognition).\n",
    "7. **Gradient Boosting (e.g., XGBoost, LightGBM)**: Boosts weak models for high accuracy (e.g., fraud detection).\n",
    "8. **Neural Networks**: Models complex patterns for tasks like speech recognition.\n",
    "\n",
    "**Unsupervised Learning Algorithms** (used with unlabeled data for pattern discovery):\n",
    "1. **K-Means Clustering**: Groups data into K clusters (e.g., customer segmentation).\n",
    "2. **DBSCAN**: Clusters data based on density, good for outliers (e.g., anomaly detection).\n",
    "3. **Hierarchical Clustering**: Builds a tree of clusters (e.g., taxonomy creation).\n",
    "4. **Principal Component Analysis (PCA)**: Reduces dimensionality for visualization or compression.\n",
    "5. **Autoencoders**: Neural networks for data reconstruction or anomaly detection.\n",
    "6. **Isolation Forest**: Detects anomalies by isolating outliers (e.g., fraud detection).\n",
    "7. **Gaussian Mixture Models (GMM)**: Models data as a mix of Gaussian distributions (e.g., image segmentation).\n",
    "8. **t-SNE**: Visualizes high-dimensional data in 2D/3D (e.g., data exploration)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105693f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
