{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab98c9af",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Q1. What is Elastic Net Regression and how does it differ from other regression techniques?**\n",
    "\n",
    "**Elastic Net Regression** combines **L1 (Lasso)** and **L2 (Ridge)** penalties in its loss function:\n",
    "\n",
    "#### ðŸ“Œ Loss Function:\n",
    "\\[\n",
    "\\text{Loss} = \\sum (y_i - \\hat{y}_i)^2 + \\lambda \\left( \\alpha \\sum |\\beta_i| + (1 - \\alpha) \\sum \\beta_i^2 \\right)\n",
    "\\]\n",
    "\n",
    "- **Î» (lambda)**: Overall regularization strength.\n",
    "- **Î± (alpha)**: Mix ratio:\n",
    "  - Î± = 1 â†’ Lasso (pure L1)\n",
    "  - Î± = 0 â†’ Ridge (pure L2)\n",
    "\n",
    "#### ðŸ” How It Differs:\n",
    "- Unlike **Ridge**, it can **select variables** (L1 effect).\n",
    "- Unlike **Lasso**, it handles **multicollinearity** better (L2 effect).\n",
    "- Offers **balanced regularization** between shrinking and selecting features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. How Do You Choose the Optimal Values of the Regularization Parameters?**\n",
    "\n",
    "There are **two tuning parameters**:\n",
    "1. **Î» (alpha in scikit-learn)**: Overall penalty strength.\n",
    "2. **Î± (l1_ratio in scikit-learn)**: Balance between L1 and L2.\n",
    "\n",
    "#### âœ… Selection Strategy:\n",
    "- Use **cross-validation** to tune both:\n",
    "  - `ElasticNetCV` in `scikit-learn` automatically tests different combinations.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, 1], alphas=[0.01, 0.1, 1, 10], cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Best alpha (Î»):\", model.alpha_)\n",
    "print(\"Best l1_ratio (Î±):\", model.l1_ratio_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. What Are the Advantages and Disadvantages of Elastic Net Regression?**\n",
    "\n",
    "| **Advantages** | **Disadvantages** |\n",
    "|----------------|-------------------|\n",
    "| Combines benefits of Ridge and Lasso | More complex to tune (2 hyperparameters) |\n",
    "| Effective with **correlated features** | Model may be harder to interpret |\n",
    "| Can **shrink and eliminate** variables | Requires feature scaling |\n",
    "| Works well with **high-dimensional data** | L1 part can be unstable with small data |\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. What Are Common Use Cases for Elastic Net Regression?**\n",
    "\n",
    "- **Genomics / Bioinformatics**: Thousands of features, but only a few relevant.\n",
    "- **Finance**: Feature selection with highly correlated economic indicators.\n",
    "- **Marketing analytics**: Predicting sales based on multiple campaigns and customer features.\n",
    "- **Text data** (with TF-IDF features): Large number of sparse, correlated inputs.\n",
    "\n",
    "Anywhere you want **robustness**, **automatic feature reduction**, and **resilience to collinearity**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q5. How Do You Interpret the Coefficients in Elastic Net Regression?**\n",
    "\n",
    "- Coefficients represent the impact of a 1-unit change in the predictor (like in OLS).\n",
    "- **Zero coefficients** mean features were removed (due to L1 penalty).\n",
    "- **Smaller coefficients** mean less influence (shrunken by L2).\n",
    "- Due to regularization, coefficients are **biased but lower variance** â€” better for prediction than inference.\n",
    "\n",
    "> ðŸ“Œ Interpretation is useful for **ranking features**, not necessarily for explaining causation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q6. How Do You Handle Missing Values When Using Elastic Net Regression?**\n",
    "\n",
    "Elastic Net (like most models in `scikit-learn`) **does not handle missing values directly**.\n",
    "\n",
    "#### âœ… Best practices:\n",
    "1. **Imputation**:\n",
    "   - Use `SimpleImputer` (mean, median, or most frequent).\n",
    "   - Or `KNNImputer` for smarter filling.\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_filled = imputer.fit_transform(X)\n",
    "```\n",
    "\n",
    "2. **Pipeline (recommended)**:\n",
    "   Combine preprocessing and modeling for reproducibility:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('model', ElasticNet(alpha=1.0, l1_ratio=0.5))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q7. How Do You Use Elastic Net for Feature Selection?**\n",
    "\n",
    "Elastic Net sets **some coefficients to zero** (like Lasso). You can select features by:\n",
    "\n",
    "```python\n",
    "# After fitting model\n",
    "import numpy as np\n",
    "\n",
    "selected_features = np.where(model.coef_ != 0)[0]\n",
    "print(\"Selected feature indices:\", selected_features)\n",
    "```\n",
    "\n",
    "ðŸ’¡ Tip: You can combine this with feature names from `pandas` to get selected feature names.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q8. How Do You Pickle and Unpickle a Trained Elastic Net Model in Python?**\n",
    "\n",
    "#### âœ… **Pickling (Saving):**\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "with open(\"elastic_net_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "```\n",
    "\n",
    "#### ðŸ”„ **Unpickling (Loading):**\n",
    "```python\n",
    "with open(\"elastic_net_model.pkl\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Use the model\n",
    "predictions = loaded_model.predict(X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q9. What Is the Purpose of Pickling a Model in Machine Learning?**\n",
    "\n",
    "Pickling is the process of **serializing a trained model** so you can:\n",
    "- **Save** it for future use (without retraining).\n",
    "- **Deploy** it in a production environment.\n",
    "- **Share** it with others or move it between systems.\n",
    "- **Speed up workflows** by avoiding retraining.\n",
    "\n",
    "Pickling is essential for **model reproducibility, deployment, and version control**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1fd3f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
